{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "name": "Rousseau.ipynb",
   "provenance": [],
   "collapsed_sections": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQY4fJl7dCwj",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Projet Voltaire 2.0 : Rousseau\n",
    "### Equipe 242\n",
    "\n",
    "\n",
    "**Etape 1** : import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten,Dropout,Conv2D\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Embedding\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Etape 2** : conversion des datasets (.csv) en dataframes pandas et retrait des valeurs aberrantes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('moyenne.csv')\n",
    "df = df.dropna()\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Etape 3** : Tokeniser les lexemes, et vectorisation des reponses"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tok = Tokenizer(char_level=True)\n",
    "tok.fit_on_texts(df.answer)\n",
    "ma = max([len(i) for i in df[\"answer\"]])\n",
    "ma\n",
    "X = tok.texts_to_sequences(df[\"answer\"])\n",
    "X = sequence.pad_sequences(X, maxlen=ma)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Etape 4** : Creation modele\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(tok.word_index)+1, 8, input_length=ma))\n",
    "model.add(Conv1D(filters=16, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=8, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Etape 5 : Entrainement Modele"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df[\"is_true\"], test_size=0.4)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "FVC-zR-Pcj8s"
   },
   "source": [],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8sCkDRIvd4z8"
   },
   "source": [
    "**Etape 2** : conversion des datasets (.csv) en dataframes pandas et retrait des valeurs aberrantes"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "3iEIVfLfeaBJ",
    "outputId": "c3b20c45-cc8f-45c7-8c33-5eeb80407867"
   },
   "source": [
    "df = pd.read_csv('moyenne.csv')\n",
    "df = df.dropna()\n",
    "df"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer</th>\n",
       "      <th>is_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HBOHBSTLHBPQHBMHBGDMaOBGDMBEBMBCCPBCGBSBTMeOBCBPM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HBOHBSTLHBPQHBMHBGDMaOBGDMBEBMBCCPBCGBSBTMeOBC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HBOHBSTLHBPQHBMHBGDMaOBGDMBEBMBCCPBCGBSBTMeOBC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HBOHBSTLHBPQHBGDMaOHBGDMBEBMBCCPQBGBCBSBTMReBCBR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HBOHBSTLHBPQHBGDMaOHBGDMBEBMBCCPQBGBCBSBTMReBCBMR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>HBOHNBLHBPQHBMHBMaOBGDMBEBMBCCPQBCGNOBCBPMReBCBMR</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>HBOHNBLHBPQHBGDMHBMaOBGDMBEBMBCCPQBCGNOBCBPMRe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>HBOHNBLHBPQHBGDLBGDMaOHBGDMBEBMBCCPQBCGNOBCBPM...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>HBOHNBLHBPQHBGDLBGDMaOHBGDMBEBMBCCPQBCGNOBCBPM...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>HBOHNBLHBPQHBGDLBGDMaOHBGDMBEBMBCCPQBCGNOBCBPM...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1842 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 answer  is_true\n",
       "0     HBOHBSTLHBPQHBMHBGDMaOBGDMBEBMBCCPBCGBSBTMeOBCBPM        0\n",
       "1     HBOHBSTLHBPQHBMHBGDMaOBGDMBEBMBCCPBCGBSBTMeOBC...        0\n",
       "2     HBOHBSTLHBPQHBMHBGDMaOBGDMBEBMBCCPBCGBSBTMeOBC...        1\n",
       "3      HBOHBSTLHBPQHBGDMaOHBGDMBEBMBCCPQBGBCBSBTMReBCBR        0\n",
       "4     HBOHBSTLHBPQHBGDMaOHBGDMBEBMBCCPQBGBCBSBTMReBCBMR        1\n",
       "...                                                 ...      ...\n",
       "2034  HBOHNBLHBPQHBMHBMaOBGDMBEBMBCCPQBCGNOBCBPMReBCBMR        1\n",
       "2035  HBOHNBLHBPQHBGDMHBMaOBGDMBEBMBCCPQBCGNOBCBPMRe...        1\n",
       "2036  HBOHNBLHBPQHBGDLBGDMaOHBGDMBEBMBCCPQBCGNOBCBPM...        1\n",
       "2037  HBOHNBLHBPQHBGDLBGDMaOHBGDMBEBMBCCPQBCGNOBCBPM...        1\n",
       "2038  HBOHNBLHBPQHBGDLBGDMaOHBGDMBEBMBCCPQBCGNOBCBPM...        1\n",
       "\n",
       "[1842 rows x 2 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 2
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0n1m5E6YffLR"
   },
   "source": [
    "**Etape 3** : Tokeniser les lexemes, et vectorisation des reponses"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KPHGYYZZfeWY"
   },
   "source": [
    "tok = Tokenizer(char_level=True)\n",
    "tok.fit_on_texts(df.answer)\n",
    "ma = max([len(i) for i in df[\"answer\"]])\n",
    "ma\n",
    "X = tok.texts_to_sequences(df[\"answer\"])\n",
    "X = sequence.pad_sequences(X, maxlen=ma)\n"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6GUjUZkiXwB"
   },
   "source": [
    "**Etape 4** : Creation modele\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JuR5ze7ui-QF",
    "outputId": "d771e426-cd14-4093-9b36-a41411f84155"
   },
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(len(tok.word_index)+1, 8, input_length=ma))\n",
    "model.add(Conv1D(filters=16, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(filters=8, kernel_size=2, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 265, 8)            176       \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 265, 16)           272       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 265, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 265, 8)            264       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 265, 8)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2120)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                67872     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 68,617\n",
      "Trainable params: 68,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kXYIofDZjmoh"
   },
   "source": [
    "Etape 5 : Entrainement Modele"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YGnxBVbVjqm7",
    "outputId": "b5413600-9681-4c8c-dc84-0941d334a968"
   },
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df[\"is_true\"], test_size=0.4)\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, batch_size=1)"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1105/1105 [==============================] - 5s 3ms/step - loss: 0.6495 - accuracy: 0.5321 - val_loss: 0.6016 - val_accuracy: 0.5142\n",
      "Epoch 2/15\n",
      "1105/1105 [==============================] - 3s 3ms/step - loss: 0.5597 - accuracy: 0.5321 - val_loss: 0.5174 - val_accuracy: 0.5142\n",
      "Epoch 3/15\n",
      "1105/1105 [==============================] - 3s 3ms/step - loss: 0.5177 - accuracy: 0.5321 - val_loss: 0.5000 - val_accuracy: 0.5142\n",
      "Epoch 4/15\n",
      "1105/1105 [==============================] - 4s 3ms/step - loss: 0.4791 - accuracy: 0.5321 - val_loss: 0.4757 - val_accuracy: 0.5142\n",
      "Epoch 5/15\n",
      "1105/1105 [==============================] - 3s 3ms/step - loss: 0.4538 - accuracy: 0.5321 - val_loss: 0.4583 - val_accuracy: 0.5142\n",
      "Epoch 6/15\n",
      "1105/1105 [==============================] - 3s 3ms/step - loss: 0.4332 - accuracy: 0.5321 - val_loss: 0.4590 - val_accuracy: 0.5142\n",
      "Epoch 7/15\n",
      "1105/1105 [==============================] - 3s 3ms/step - loss: 0.4106 - accuracy: 0.5321 - val_loss: 0.4572 - val_accuracy: 0.5142\n",
      "Epoch 8/15\n",
      "1105/1105 [==============================] - 3s 3ms/step - loss: 0.4087 - accuracy: 0.5321 - val_loss: 0.4448 - val_accuracy: 0.5142\n",
      "Epoch 9/15\n",
      "1105/1105 [==============================] - 3s 3ms/step - loss: 0.3751 - accuracy: 0.5321 - val_loss: 0.4510 - val_accuracy: 0.5142\n",
      "Epoch 10/15\n",
      "1105/1105 [==============================] - 3s 3ms/step - loss: 0.3778 - accuracy: 0.5321 - val_loss: 0.4320 - val_accuracy: 0.5142\n",
      "Epoch 11/15\n",
      "1105/1105 [==============================] - 3s 3ms/step - loss: 0.3590 - accuracy: 0.5321 - val_loss: 0.4317 - val_accuracy: 0.5142\n",
      "Epoch 12/15\n",
      "1105/1105 [==============================] - 3s 3ms/step - loss: 0.3734 - accuracy: 0.5321 - val_loss: 0.4239 - val_accuracy: 0.5142\n",
      "Epoch 13/15\n",
      "1105/1105 [==============================] - 3s 3ms/step - loss: 0.3433 - accuracy: 0.5321 - val_loss: 0.4264 - val_accuracy: 0.5142\n",
      "Epoch 14/15\n",
      "1105/1105 [==============================] - 4s 3ms/step - loss: 0.3453 - accuracy: 0.5321 - val_loss: 0.4256 - val_accuracy: 0.5142\n",
      "Epoch 15/15\n",
      "1105/1105 [==============================] - 3s 3ms/step - loss: 0.3312 - accuracy: 0.5321 - val_loss: 0.4429 - val_accuracy: 0.5142\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa5cc5c8210>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3liMGEr9jpnv"
   },
   "source": [
    ""
   ]
  }
 ]
}